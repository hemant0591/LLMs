{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp 2>/dev/null  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:18:46.392137Z","iopub.execute_input":"2025-11-17T11:18:46.392533Z","iopub.status.idle":"2025-11-17T11:18:56.143120Z","shell.execute_reply.started":"2025-11-17T11:18:46.392503Z","shell.execute_reply":"2025-11-17T11:18:56.141901Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.18.0 requires google-genai<2.0.0,>=1.45.0, but you have google-genai 1.7.0 which is incompatible.\ngoogle-cloud-aiplatform 1.125.0 requires google-genai<2.0.0,>=1.37.0, but you have google-genai 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:18:56.145372Z","iopub.execute_input":"2025-11-17T11:18:56.145712Z","iopub.status.idle":"2025-11-17T11:18:58.058035Z","shell.execute_reply.started":"2025-11-17T11:18:56.145677Z","shell.execute_reply":"2025-11-17T11:18:58.056996Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:18:58.058941Z","iopub.execute_input":"2025-11-17T11:18:58.059419Z","iopub.status.idle":"2025-11-17T11:18:58.640668Z","shell.execute_reply.started":"2025-11-17T11:18:58.059393Z","shell.execute_reply":"2025-11-17T11:18:58.639611Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\ntrain = fetch_20newsgroups(subset=\"train\")\ntest = fetch_20newsgroups(subset=\"test\")\n\ntrain.target_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:18:58.641755Z","iopub.execute_input":"2025-11-17T11:18:58.642349Z","iopub.status.idle":"2025-11-17T11:19:08.565453Z","shell.execute_reply.started":"2025-11-17T11:18:58.642310Z","shell.execute_reply":"2025-11-17T11:19:08.564509Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"print(train.data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:08.567822Z","iopub.execute_input":"2025-11-17T11:19:08.568302Z","iopub.status.idle":"2025-11-17T11:19:08.574203Z","shell.execute_reply.started":"2025-11-17T11:19:08.568278Z","shell.execute_reply":"2025-11-17T11:19:08.572756Z"}},"outputs":[{"name":"stdout","text":"From: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n\n\n\n\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"#### Preprocess text","metadata":{}},{"cell_type":"code","source":"import email\nimport re\n\nimport pandas as pd\n\n\ndef preprocess_newsgroup_row(data):\n    # Extract only the subject and body\n    msg = email.message_from_string(data)\n    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n    # Strip any remaining email addresses\n    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n    # Truncate each entry to 5,000 characters\n    text = text[:5000]\n\n    return text\n\n\ndef preprocess_newsgroup_data(newsgroup_dataset):\n    # Put data points into dataframe\n    df = pd.DataFrame(\n        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n    )\n    # Clean up the text\n    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n    # Match label to target name index\n    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:08.575240Z","iopub.execute_input":"2025-11-17T11:19:08.575523Z","iopub.status.idle":"2025-11-17T11:19:09.148013Z","shell.execute_reply.started":"2025-11-17T11:19:08.575500Z","shell.execute_reply":"2025-11-17T11:19:09.146423Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_train = preprocess_newsgroup_data(train)\ndf_test = preprocess_newsgroup_data(test)\n\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:09.149260Z","iopub.execute_input":"2025-11-17T11:19:09.149896Z","iopub.status.idle":"2025-11-17T11:19:12.669133Z","shell.execute_reply.started":"2025-11-17T11:19:09.149865Z","shell.execute_reply":"2025-11-17T11:19:12.667803Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                Text  Label  \\\n0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n\n              Class Name  \n0              rec.autos  \n1  comp.sys.mac.hardware  \n2  comp.sys.mac.hardware  \n3          comp.graphics  \n4              sci.space  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n      <td>14</td>\n      <td>sci.space</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def sample_data(df, num_samples, classes_to_keep):\n    # Sample rows, selecting num_samples of each Label.\n    df = (\n        df.groupby(\"Label\")[df.columns]\n        .apply(lambda x: x.sample(num_samples))\n        .reset_index(drop=True)\n    )\n\n    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n\n    # We have fewer categories now, so re-calibrate the label encoding.\n    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:12.670750Z","iopub.execute_input":"2025-11-17T11:19:12.671144Z","iopub.status.idle":"2025-11-17T11:19:12.677138Z","shell.execute_reply.started":"2025-11-17T11:19:12.671111Z","shell.execute_reply":"2025-11-17T11:19:12.675884Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"TRAIN_NUM_SAMPLES = 100\nTEST_NUM_SAMPLES = 25\n# Class name should contain 'sci' to keep science categories.\nCLASSES_TO_KEEP = \"sci\"\n\ndf_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\ndf_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:12.678015Z","iopub.execute_input":"2025-11-17T11:19:12.678311Z","iopub.status.idle":"2025-11-17T11:19:12.742846Z","shell.execute_reply.started":"2025-11-17T11:19:12.678281Z","shell.execute_reply":"2025-11-17T11:19:12.741669Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_train.value_counts(\"Class Name\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:12.743926Z","iopub.execute_input":"2025-11-17T11:19:12.744190Z","iopub.status.idle":"2025-11-17T11:19:12.754302Z","shell.execute_reply.started":"2025-11-17T11:19:12.744169Z","shell.execute_reply":"2025-11-17T11:19:12.753421Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Class Name\nsci.crypt          100\nsci.electronics    100\nsci.med            100\nsci.space          100\nName: count, dtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### create embeddings","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\nimport tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\ntqdmr.pandas()\n\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n# create a helper function\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n@retry.Retry(predicate=is_retriable, timeout=300.0)\ndef get_embeddings(text):\n    response = client.models.embed_content(\n        model=\"models/text-embedding-004\",\n        contents=text,\n        config=types.EmbedContentConfig(\n            task_type=\"classification\",\n        ),\n    )\n\n    return response.embeddings[0].values\n\ndef create_embeddings(df):\n    df[\"Embeddings\"] = df[\"Text\"].progress_apply(get_embeddings)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:12.755498Z","iopub.execute_input":"2025-11-17T11:19:12.755813Z","iopub.status.idle":"2025-11-17T11:19:15.443309Z","shell.execute_reply.started":"2025-11-17T11:19:12.755790Z","shell.execute_reply":"2025-11-17T11:19:15.442013Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_train = create_embeddings(df_train)\ndf_test = create_embeddings(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:19:15.444349Z","iopub.execute_input":"2025-11-17T11:19:15.444891Z","iopub.status.idle":"2025-11-17T11:21:05.936554Z","shell.execute_reply.started":"2025-11-17T11:19:15.444859Z","shell.execute_reply":"2025-11-17T11:21:05.935191Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5050a8292e1d49599f6b6a093ee00937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23733193f8a84c36affff8ddc3cee747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:05.937945Z","iopub.execute_input":"2025-11-17T11:21:05.938435Z","iopub.status.idle":"2025-11-17T11:21:05.955990Z","shell.execute_reply.started":"2025-11-17T11:21:05.938399Z","shell.execute_reply":"2025-11-17T11:21:05.955005Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label Class Name  \\\n1100  The battle is joined\\n\\nIt looks like Dorothy ...     11  sci.crypt   \n1101  are we being hysterical? No!\\n\\n\\nIn article <...     11  sci.crypt   \n1102  Re: text of White House announcement and Q&As ...     11  sci.crypt   \n1103  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n1104  Re: Clipper considered harmful\\n\\nIn article <...     11  sci.crypt   \n\n      Encoded Label                                         Embeddings  \n1100              0  [0.010916892, 0.015981745, -0.05892634, 0.0188...  \n1101              0  [0.012027563, 0.025119599, -0.058926936, -0.00...  \n1102              0  [-0.015403877, 0.030044148, -0.037202857, 0.03...  \n1103              0  [0.0045050536, 0.020362409, -0.061563283, 0.00...  \n1104              0  [0.004346496, 0.029194878, -0.06622962, 0.0297...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n      <th>Encoded Label</th>\n      <th>Embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1100</th>\n      <td>The battle is joined\\n\\nIt looks like Dorothy ...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.010916892, 0.015981745, -0.05892634, 0.0188...</td>\n    </tr>\n    <tr>\n      <th>1101</th>\n      <td>are we being hysterical? No!\\n\\n\\nIn article &lt;...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.012027563, 0.025119599, -0.058926936, -0.00...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>Re: text of White House announcement and Q&amp;As ...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.015403877, 0.030044148, -0.037202857, 0.03...</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Re: Once tapped, your code is no good any more...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.0045050536, 0.020362409, -0.061563283, 0.00...</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Re: Clipper considered harmful\\n\\nIn article &lt;...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.004346496, 0.029194878, -0.06622962, 0.0297...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Build a classification model","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# class ClassificationModel(nn.Module):\n#     def __init__(self, input_size, hidden_dim, num_classes):\n#         super(ClassificationModel, self).__init__()\n#         self.hidden = nn.Linear(input_size, hidden_dim)\n#         self.output = nn.Linear(hidden_dim, num_classes)\n\n#     def forward(self, x):\n#         x = F.relu(self.hidden(x))\n#         x = self.output(x)\n#         return x        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:05.959560Z","iopub.execute_input":"2025-11-17T11:21:05.960045Z","iopub.status.idle":"2025-11-17T11:21:05.978087Z","shell.execute_reply.started":"2025-11-17T11:21:05.960020Z","shell.execute_reply":"2025-11-17T11:21:05.976780Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# input_size = len(df_train['Embeddings'].iloc[0])\n# num_classes = df_train['Encoded Label'].nunique()\n\n# input_size, num_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:05.979309Z","iopub.execute_input":"2025-11-17T11:21:05.980193Z","iopub.status.idle":"2025-11-17T11:21:05.999438Z","shell.execute_reply.started":"2025-11-17T11:21:05.980162Z","shell.execute_reply":"2025-11-17T11:21:05.998305Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# model = ClassificationModel(input_size, input_size, num_classes)\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.000684Z","iopub.execute_input":"2025-11-17T11:21:06.001000Z","iopub.status.idle":"2025-11-17T11:21:06.020303Z","shell.execute_reply.started":"2025-11-17T11:21:06.000976Z","shell.execute_reply":"2025-11-17T11:21:06.019112Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# for name, param in model.named_parameters():\n#     if param.requires_grad:\n#         print(f\"name: {name}, parama_count: {param.shape}, total_params: {param.numel()}\")\n#         print()\n\n# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# total_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.021800Z","iopub.execute_input":"2025-11-17T11:21:06.022121Z","iopub.status.idle":"2025-11-17T11:21:06.041741Z","shell.execute_reply.started":"2025-11-17T11:21:06.022097Z","shell.execute_reply":"2025-11-17T11:21:06.040349Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"# from torch.utils.data import DataLoader, TensorDataset\n# from torch.optim import Adam\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# NUM_EPOCHS = 20\n# BATCH_SIZE = 32\n# PATIENCE = 3\n# LR = 1e-3\n\n# x_train = torch.tensor(np.stack(df_train['Embeddings'].values), dtype=torch.float32)\n# y_train = torch.tensor(df_train['Encoded Label'].values, dtype=torch.long)\n\n# x_val = torch.tensor(np.stack(df_test['Embeddings'].values), dtype=torch.float32)\n# y_val = torch.tensor(df_test['Encoded Label'].values, dtype=torch.long)\n\n# train_dataset = TensorDataset(x_train, y_train)\n# test_dataset = TensorDataset(x_val, y_val)\n\n# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# val_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n# model.to(device)\n\n# criterion = nn.CrossEntropyLoss()\n# optimizer = Adam(model.parameters(), lr=LR)\n\n# train_losses, train_accs = [], []\n# val_losses, val_accs = [], []\n\n# best_val_acc = 0\n# patience_counter = 0\n# best_state = None\n\n# for epoch in range(1, NUM_EPOCHS + 1):\n#     # training\n#     model.train()\n#     running_loss = 0.\n#     correct = 0\n#     total = 0\n\n#     for xb, yb in train_dataloader:\n#         xb, yb = xb.to(device), yb.to(device)\n#         optimizer.zero_grad()\n#         logits = model(xb)\n#         loss = criterion(logits, yb)\n#         loss.backward()\n#         optimizer.step()\n\n#         running_loss += loss.item() * xb.size(0)\n#         preds = logits.argmax(dim=1)\n#         correct += (preds == yb).sum().item()\n#         total += xb.size(0)\n\n#     epoch_train_loss = running_loss / total\n#     epoch_train_acc = correct / total\n#     train_losses.append(epoch_train_loss)\n#     train_accs.append(epoch_train_acc)\n\n#     # validation\n#     model.eval()\n#     val_running_loss = 0.\n#     val_correct = 0\n#     val_total = 0\n\n#     with torch.no_grad():\n#         for xb, yb in val_dataloader:\n#             xb, yb = xb.to(device), yb.to(device)\n#             logits = model(xb)\n#             loss = criterion(logits, yb)\n#             val_running_loss += loss.item() * xb.size(0)\n#             preds = logits.argmax(dim=1)\n#             val_correct += (preds == yb).sum().item()\n#             val_total += xb.size(0)\n\n#         epoch_val_loss = val_running_loss / total\n#         epoch_val_acc = val_correct / total\n#         val_losses.append(epoch_val_loss)\n#         val_accs.append(epoch_val_acc)\n\n#     print(\n#         f\"Epoch {epoch}/{NUM_EPOCHS} \"\n#         f\"Train loss: {epoch_train_loss:.4f}, Train acc: {epoch_train_acc:.4f} | \"\n#         f\"Val loss: {epoch_val_loss:.4f}, Val acc: {epoch_val_acc:.4f}\"\n#     )\n\n#     if epoch_val_acc > best_val_acc:\n#         best_val_acc = epoch_val_acc\n#         best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n#         patience_counter = 0\n\n#     else:\n#         patience_counter += 1\n#         if patience_counter >= PATIENCE:\n#             print(f\"Early stopping at epoch {epoch} (no improvement in val acc for {PATIENCE} epochs).\")\n#             break\n\n# if best_state is not None:\n#     model.load_state_dict(best_state)\n#     print(f\"Loaded best model with val acc: {best_val_acc:.4f}\")\n\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, len(train_accs) + 1), train_accs, label=\"Train Acc\")\n# plt.plot(range(1, len(val_accs) + 1), val_accs, label=\"Val Acc\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"Accuracy\")\n# plt.title(\"Accuracy\")\n# plt.legend()\n# plt.grid(True)\n\n# # Loss subplot\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\n# plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Val Loss\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"Loss\")\n# plt.title(\"Loss\")\n# plt.legend()\n# plt.grid(True)\n\n# plt.tight_layout()\n# plt.show()\n\n# # ---------- Optional: save history and model ----------\n# history = {\n#     \"train_losses\": train_losses,\n#     \"train_accs\": train_accs,\n#     \"val_losses\": val_losses,\n#     \"val_accs\": val_accs,\n# }\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.043067Z","iopub.execute_input":"2025-11-17T11:21:06.043414Z","iopub.status.idle":"2025-11-17T11:21:06.067773Z","shell.execute_reply.started":"2025-11-17T11:21:06.043382Z","shell.execute_reply":"2025-11-17T11:21:06.066570Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# model.eval()\n# criterion = torch.nn.CrossEntropyLoss()\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# val_loss, val_correct, val_total = 0.0, 0, 0\n\n# with torch.no_grad():\n#     for xb, yb in val_dataloader:\n#         xb, yb = xb.to(device), yb.to(device)\n#         preds = model(xb)\n#         loss = criterion(preds, yb)\n#         val_loss += loss.item() * xb.size(0)\n\n#         _, predicted = torch.max(preds, 1)\n#         val_correct += (predicted == yb).sum().item()\n#         val_total += yb.size(0)\n\n# # Compute metrics\n# avg_val_loss = val_loss / val_total\n# val_accuracy = val_correct / val_total\n\n# # Return dict (like return_dict=True)\n# results = {\n#     \"val_loss\": avg_val_loss,\n#     \"val_accuracy\": val_accuracy,\n# }\n\n# print(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.068600Z","iopub.execute_input":"2025-11-17T11:21:06.068887Z","iopub.status.idle":"2025-11-17T11:21:06.092829Z","shell.execute_reply.started":"2025-11-17T11:21:06.068865Z","shell.execute_reply":"2025-11-17T11:21:06.091759Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# import keras\n# from keras import layers\n\n\n# def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n#     return keras.Sequential(\n#         [\n#             layers.Input([input_size], name=\"embedding_inputs\"),\n#             layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n#             layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n#         ]\n#     )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.093990Z","iopub.execute_input":"2025-11-17T11:21:06.094427Z","iopub.status.idle":"2025-11-17T11:21:06.118292Z","shell.execute_reply.started":"2025-11-17T11:21:06.094309Z","shell.execute_reply":"2025-11-17T11:21:06.117298Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n\n# classifier = build_classification_model(\n#     embedding_size, len(df_train[\"Class Name\"].unique())\n# )\n# classifier.summary()\n\n# classifier.compile(\n#     loss=keras.losses.SparseCategoricalCrossentropy(),\n#     optimizer=keras.optimizers.Adam(learning_rate=0.001),\n#     metrics=[\"accuracy\"],\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.119498Z","iopub.execute_input":"2025-11-17T11:21:06.120367Z","iopub.status.idle":"2025-11-17T11:21:06.138599Z","shell.execute_reply.started":"2025-11-17T11:21:06.120338Z","shell.execute_reply":"2025-11-17T11:21:06.137360Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# import numpy as np\n\n\n# NUM_EPOCHS = 20\n# BATCH_SIZE = 32\n\n# # Split the x and y components of the train and validation subsets.\n# y_train = df_train[\"Encoded Label\"]\n# x_train = np.stack(df_train[\"Embeddings\"])\n# y_val = df_test[\"Encoded Label\"]\n# x_val = np.stack(df_test[\"Embeddings\"])\n\n# # Specify that it's OK to stop early if accuracy stabilises.\n# early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n\n# # Train the model for the desired number of epochs.\n# history = classifier.fit(\n#     x=x_train,\n#     y=y_train,\n#     validation_data=(x_val, y_val),\n#     callbacks=[early_stop],\n#     batch_size=BATCH_SIZE,\n#     epochs=NUM_EPOCHS,\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.139735Z","iopub.execute_input":"2025-11-17T11:21:06.140051Z","iopub.status.idle":"2025-11-17T11:21:06.158766Z","shell.execute_reply.started":"2025-11-17T11:21:06.140026Z","shell.execute_reply":"2025-11-17T11:21:06.157627Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# classifier.evaluate(x=x_val, y=y_val, return_dict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:06.160041Z","iopub.execute_input":"2025-11-17T11:21:06.160349Z","iopub.status.idle":"2025-11-17T11:21:06.184377Z","shell.execute_reply.started":"2025-11-17T11:21:06.160325Z","shell.execute_reply":"2025-11-17T11:21:06.183004Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.cuda.amp import GradScaler, autocast\nimport time\n\n# ============================\n# === CONFIG / HYPERPARAMS ===\n# ============================\nNUM_EPOCHS = 20\nBATCH_SIZE = 32\nLR = 1e-3\nPATIENCE = 3\nWEIGHT_DECAY = 0.0\nNUM_WORKERS = 4          # adjust to your environment\nPREFETCH_FACTOR = 2\nPIN_MEMORY = True\nSEED = 42\n\n# ===============================\n# === REPRODUCIBILITY / SPEED ===\n# ===============================\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.benchmark = True   # enable cuDNN autotuner for best conv performance\n\n# ============================\n# === DATA PREPARATION (YOU) ==\n# ============================\n# Expect df_train and df_val to exist and contain:\n#   df_train[\"Embeddings\"] -> sequence-like per-row (list/np.array)\n#   df_train[\"Encoded Label\"] -> integer labels\n#\n# Convert to numpy then tensors\n\n# Example:\n# x_train = np.stack(df_train[\"Embeddings\"].values).astype(np.float32)\n# y_train = df_train[\"Encoded Label\"].values.astype(np.int64)\n# x_val   = np.stack(df_val[\"Embeddings\"].values).astype(np.float32)\n# y_val   = df_val[\"Encoded Label\"].values.astype(np.int64)\n\n# Replace below placeholders with actual conversion\nx_train = np.stack(df_train[\"Embeddings\"].values).astype(np.float32)\ny_train = df_train[\"Encoded Label\"].values.astype(np.int64)\nx_val   = np.stack(df_test[\"Embeddings\"].values).astype(np.float32)\ny_val   = df_test[\"Encoded Label\"].values.astype(np.int64)\n\ntrain_tensor_x = torch.from_numpy(x_train)\ntrain_tensor_y = torch.from_numpy(y_train)\nval_tensor_x = torch.from_numpy(x_val)\nval_tensor_y = torch.from_numpy(y_val)\n\ntrain_ds = TensorDataset(train_tensor_x, train_tensor_y)\nval_ds = TensorDataset(val_tensor_x, val_tensor_y)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=PIN_MEMORY,\n    prefetch_factor=PREFETCH_FACTOR\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=PIN_MEMORY,\n    prefetch_factor=PREFETCH_FACTOR\n)\n\n# ============================\n# === MODEL DEFINITION =======\n# ============================\nclass ClassificationModel(nn.Module):\n    def __init__(self, input_size: int, num_classes: int):\n        super().__init__()\n        self.hidden = nn.Linear(input_size, input_size)\n        self.output = nn.Linear(input_size, num_classes)\n        # optional: initialize like Keras (Glorot/Xavier uniform)\n        nn.init.xavier_uniform_(self.hidden.weight)\n        nn.init.zeros_(self.hidden.bias)\n        nn.init.xavier_uniform_(self.output.weight)\n        nn.init.zeros_(self.output.bias)\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))\n        return self.output(x)   # raw logits (no softmax)\n\ninput_size = train_tensor_x.shape[1]\nnum_classes = int(np.unique(y_train).shape[0])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ClassificationModel(input_size, num_classes).to(device)\n\n# ============================\n# === LOSS / OPT / AMP =======\n# ============================\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, eps=1e-7, weight_decay=WEIGHT_DECAY)\nscaler = GradScaler(enabled=torch.cuda.is_available())  # mixed precision if GPU available\n\n# ============================\n# === TRAINING LOOP ==========\n# ============================\nhistory = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\nbest_val_acc = -np.inf\nbest_state = None\npatience_counter = 0\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    epoch_start = time.time()\n    # ---- train ----\n    model.train()\n    train_loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    for xb, yb in train_loader:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n        with autocast(enabled=torch.cuda.is_available()):\n            logits = model(xb)\n            loss = criterion(logits, yb)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss_sum += loss.item() * xb.size(0)\n        preds = logits.argmax(dim=1)\n        correct += (preds == yb).sum().item()\n        total += xb.size(0)\n\n    train_loss = train_loss_sum / total\n    train_acc = correct / total\n\n    # ---- validate ----\n    model.eval()\n    val_loss_sum = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            with autocast(enabled=torch.cuda.is_available()):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n            val_loss_sum += loss.item() * xb.size(0)\n            preds = logits.argmax(dim=1)\n            val_correct += (preds == yb).sum().item()\n            val_total += xb.size(0)\n\n    val_loss = val_loss_sum / val_total\n    val_acc = val_correct / val_total\n\n    history[\"train_loss\"].append(train_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_acc\"].append(val_acc)\n\n    epoch_time = time.time() - epoch_start\n    print(\n        f\"Epoch {epoch:02d}/{NUM_EPOCHS} \"\n        f\"time={epoch_time:.1f}s \"\n        f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} \"\n        f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\"\n    )\n\n    # ---- early stopping / best model\n    if val_acc > best_val_acc + 1e-12:\n        best_val_acc = val_acc\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= PATIENCE:\n            print(f\"Early stopping: no improvement in val_acc for {PATIENCE} epochs.\")\n            break\n\n# restore best model weights\nif best_state is not None:\n    model.load_state_dict(best_state)\n    model.to(device)\n    print(f\"Restored best model with val_acc={best_val_acc:.4f}\")\n\n# Save model if desired\n# torch.save(model.state_dict(), \"best_model.pt\")\n\n# history is identical-ish to Keras history\nprint(\"Training finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:21:47.348037Z","iopub.execute_input":"2025-11-17T11:21:47.348406Z","iopub.status.idle":"2025-11-17T11:21:58.382781Z","shell.execute_reply.started":"2025-11-17T11:21:47.348381Z","shell.execute_reply":"2025-11-17T11:21:58.381589Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_48/3112587956.py:109: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=torch.cuda.is_available())  # mixed precision if GPU available\n/tmp/ipykernel_48/3112587956.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01/20 time=0.5s train_loss=1.3642 train_acc=0.3925 val_loss=1.2985 val_acc=0.3800\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/3112587956.py:157: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02/20 time=0.5s train_loss=1.2179 train_acc=0.5625 val_loss=1.1782 val_acc=0.6900\nEpoch 03/20 time=0.4s train_loss=1.0719 train_acc=0.7125 val_loss=1.0742 val_acc=0.6400\nEpoch 04/20 time=0.4s train_loss=0.9219 train_acc=0.8100 val_loss=0.9235 val_acc=0.7800\nEpoch 05/20 time=0.4s train_loss=0.7435 train_acc=0.8950 val_loss=0.7667 val_acc=0.8400\nEpoch 06/20 time=0.4s train_loss=0.5949 train_acc=0.9275 val_loss=0.6634 val_acc=0.8000\nEpoch 07/20 time=0.4s train_loss=0.4740 train_acc=0.9500 val_loss=0.5381 val_acc=0.8900\nEpoch 08/20 time=0.4s train_loss=0.3910 train_acc=0.9500 val_loss=0.4780 val_acc=0.9000\nEpoch 09/20 time=0.4s train_loss=0.3005 train_acc=0.9625 val_loss=0.4017 val_acc=0.9200\nEpoch 10/20 time=0.4s train_loss=0.2522 train_acc=0.9625 val_loss=0.3856 val_acc=0.9000\nEpoch 11/20 time=0.4s train_loss=0.2320 train_acc=0.9750 val_loss=0.3388 val_acc=0.9300\nEpoch 12/20 time=0.9s train_loss=0.1921 train_acc=0.9775 val_loss=0.3386 val_acc=0.9300\nEpoch 13/20 time=0.4s train_loss=0.1630 train_acc=0.9825 val_loss=0.2925 val_acc=0.9600\nEpoch 14/20 time=0.4s train_loss=0.1365 train_acc=0.9850 val_loss=0.2878 val_acc=0.9300\nEpoch 15/20 time=0.4s train_loss=0.1239 train_acc=0.9900 val_loss=0.2842 val_acc=0.9400\nEpoch 16/20 time=0.4s train_loss=0.1122 train_acc=0.9925 val_loss=0.2706 val_acc=0.9400\nEarly stopping: no improvement in val_acc for 3 epochs.\nRestored best model with val_acc=0.9600\nTraining finished.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def make_prediction(text: str) -> list[float]:\n    \"\"\"Infer category probabilities from the provided text.\"\"\"\n    # Get embedding (this depends on your embedding function)\n    embedded = get_embeddings(text)     # should return a list or numpy array\n    if isinstance(embedded, list):\n        embedded = np.array(embedded, dtype=np.float32)\n    if embedded.ndim == 1:\n        embedded = embedded[np.newaxis, :]  # make it a batch of 1\n\n    # Convert to torch tensor\n    inp = torch.tensor(embedded, dtype=torch.float32).to(device)\n\n    # Inference mode (no gradients)\n    model.eval()\n    with torch.no_grad():\n        logits = model(inp)\n        probs = torch.softmax(logits, dim=1)  # convert to probabilities\n        probs = probs.cpu().numpy().flatten().tolist()\n\n    return probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:24:13.178165Z","iopub.execute_input":"2025-11-17T11:24:13.180017Z","iopub.status.idle":"2025-11-17T11:24:13.188222Z","shell.execute_reply.started":"2025-11-17T11:24:13.179972Z","shell.execute_reply":"2025-11-17T11:24:13.187204Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"new_text = \"\"\"\nFirst-timer looking to get out of here.\n\nHi, I'm writing about my interest in travelling to the outer limits!\n\nWhat kind of craft can I buy? What is easiest to access from this 3rd rock?\n\nLet me know how to do that please.\n\"\"\"\n\nresult = make_prediction(new_text)\n\nfor idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n    print(f\"{category}: {result[idx] * 100:0.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T11:24:49.616388Z","iopub.execute_input":"2025-11-17T11:24:49.617184Z","iopub.status.idle":"2025-11-17T11:24:49.916610Z","shell.execute_reply.started":"2025-11-17T11:24:49.617153Z","shell.execute_reply":"2025-11-17T11:24:49.915346Z"}},"outputs":[{"name":"stdout","text":"sci.crypt: 0.20%\nsci.electronics: 0.22%\nsci.med: 0.14%\nsci.space: 99.43%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}