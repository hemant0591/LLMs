{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(1) Numeric Example: KV(prefix) is invariant to suffix\n",
        "\n",
        "We will use a tiny causal transformer with:\n",
        "\n",
        "\t•\tvocab → toy integers\n",
        "\t•\tembedding size → 2\n",
        "\t•\t1 attention layer\n",
        "\t•\tQ/K/V are linear projections\n",
        "\n",
        "We show how token #1 and #2 KV are the same, even if the suffix changes.\n",
        "\n",
        "Prompt A: Tell me a joke.\n",
        "\n",
        "Tokens: [10, 20, 30, 40]\n",
        "\n",
        "Prompt B: Tell me a riddle\n",
        "Tokens: [10, 20, 30, 99]\n",
        "\n",
        "The prefix is: [10, 20, 30]\n",
        "\n",
        "Embeddings:\n",
        "\n",
        "E(10) = [1, 0]\n",
        "\n",
        "E(20) = [0, 1]\n",
        "\n",
        "E(30) = [1, 1]\n",
        "\n",
        "E(40) = [2, 0]\n",
        "\n",
        "E(99) = [0, 2]\n",
        "\n",
        "Linear Projections\n",
        "\n",
        "Wk = [[1, 0], [0, 1]]   -> identity\n",
        "\n",
        "Wv = [[1, 0], [0, 1]]   -> identity\n",
        "\n",
        "Compute K/V for prefix:\n",
        "\n",
        "Token 10\n",
        "\n",
        "K10 = Wk * [1,0] = [1,0]\n",
        "\n",
        "V10 = Wv * [1,0] = [1,0]\n",
        "\n",
        "Token 20\n",
        "\n",
        "K20 = [0,1]\n",
        "\n",
        "V20 = [0,1]\n",
        "\n",
        "Token 30\n",
        "\n",
        "K30 = [1,1]\n",
        "\n",
        "V30 = [1,1]\n",
        "\n",
        "These K/V values do not depend on tokens 40 or 99.\n",
        "\n",
        "So regardless of the suffix:\n",
        "\n",
        "Prompt A (10,20,30,40) produces:\n",
        "\n",
        "Prefix K = [[1,0], [0,1], [1,1]]\n",
        "\n",
        "Prefix V = [[1,0], [0,1], [1,1]]\n",
        "\n",
        "Prompt B (10,20,30,99) produces:\n",
        "\n",
        "Prefix K = [[1,0], [0,1], [1,1]]\n",
        "\n",
        "Prefix V = [[1,0], [0,1], [1,1]]\n",
        "\n",
        "Because the projections depend only on prefix embeddings, not on future tokens.\n",
        "\n",
        "This generalizes exactly to real transformers with many layers:\n",
        "K/V for token t depend only on tokens 1…t."
      ],
      "metadata": {
        "id": "MHzOF5Jy2VcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How vLLM Detects Shared Prefixes (Exact Token-Level Match)\n",
        "\n",
        "vLLM implements prefix caching using a structure called PagedAttention which stores KV in “virtual memory pages.”\n",
        "\n",
        "How vLLM matches prefixes across sequences\n",
        "\n",
        "vLLM:\n",
        "\n",
        "\t1.\tTokenizes the input\n",
        "\t2.\tStores tokens in a “KV page table”\n",
        "\t3.\tCompares new token sequences with existing cached ones\n",
        "\t4.\tFinds the longest common prefix\n",
        "\t5.\tReuses all KV pages corresponding to that prefix\n",
        "\t6.\tComputes only the new suffix tokens\n",
        "\t7.\tAppends KV pages for the new tokens\n",
        "\n",
        "Example:\n",
        "\n",
        "Cached request:\n",
        "\n",
        "[User: Tell me a]\n",
        "\n",
        "New request\n",
        "\n",
        "[User: Tell me a joke]\n",
        "\n",
        "Common prefix = [User:, Tell, me, a]\n",
        "\n",
        "New tokens = [joke]\n",
        "\n",
        "It then:\n",
        "\n",
        "\t•\tReuses all KV pages for prefix\n",
        "\t•\tOnly runs the model for “joke”\n"
      ],
      "metadata": {
        "id": "uz_a9WU33J6T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUSgNfuK3WCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}